# ConfiguraciÃ³n de LLMs RÃ¡pidos para Connie

## ğŸš€ Proveedores Ultra RÃ¡pidos (Recomendados)

### 1. **Groq** âš¡ (MÃS RÃPIDO - GRATIS)

**Ventajas:**
- âœ… **Ultra rÃ¡pido** - Hasta 10x mÃ¡s rÃ¡pido que OpenAI
- âœ… **100% GRATIS** - 14,400 requests/dÃ­a gratis
- âœ… Modelos potentes (Llama 3.1, Mixtral)
- âœ… Sin lÃ­mites de velocidad

**ConfiguraciÃ³n:**
1. Ve a https://console.groq.com
2. Crea cuenta gratuita
3. Genera API Key
4. Agrega a Vercel: `GROQ_API_KEY=tu_api_key`
5. Agrega: `LLM_PROVIDER=groq`

**Precio:** Gratis hasta 14,400 requests/dÃ­a

---

## âš¡ Optimizaciones para OpenAI (Actual)

Si prefieres seguir con OpenAI, estas optimizaciones ya estÃ¡n aplicadas:

1. âœ… **Modelo rÃ¡pido**: `gpt-4o-mini` (ya configurado)
2. âœ… **Max tokens reducido**: 1500 (antes 2000)
3. âœ… **Contexto limitado**: Solo Ãºltimos 10 mensajes
4. â³ **Streaming**: Pendiente de implementar

---

## ğŸ¯ RecomendaciÃ³n

**Para mÃ¡xima velocidad:**
1. **Groq** - Si quieres lo mÃ¡s rÃ¡pido posible (GRATIS) â­ RECOMENDADO
2. **OpenAI optimizado** - Si ya tienes todo configurado y prefieres confiabilidad

---

## ğŸ“ Variables de Entorno en Vercel

Agrega estas variables segÃºn el proveedor que elijas:

### Para Groq (Recomendado para velocidad):
```
GROQ_API_KEY=tu_api_key_de_groq
LLM_PROVIDER=groq
```

### Para OpenAI (Por defecto):
```
CHAT_GPT_KEY=tu_api_key_de_openai
LLM_PROVIDER=openai
```

---

## ğŸ”„ Cambiar Proveedor

Solo cambia la variable `LLM_PROVIDER` en Vercel y redepleya. El cÃ³digo detectarÃ¡ automÃ¡ticamente el proveedor configurado.

